{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e542f02f-2ba9-4eda-a521-55e12bf28178",
    "_uuid": "03e7f1631f5f3adbbd04b3dfbbfc7bb9c9b90b8d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = glob.glob('train/*/*.png')\n",
    "#z = glob.glob('test_train/*/*.png')\n",
    "ori_label = []\n",
    "ori_imgs = []\n",
    "for fn in z:\n",
    "    if fn[-3:] != 'png':\n",
    "        continue\n",
    "    ori_label.append(fn.split('/')[-2])\n",
    "    new_img = Image.open(fn)\n",
    "    ori_imgs.append(ImageOps.fit(new_img, (48, 48), Image.ANTIALIAS).convert('RGB'))\n",
    "#print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "545b72a2-edd6-4b1c-acb6-93e407169ab2",
    "_uuid": "3a3cda504c889472a7e5c16c95478b22a317a9ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAIAAADYYG7QAAATQUlEQVR4nAXB2Y5kV3YY0H3mc+cb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\nDlhpkPz/A3/b0GqPxFncAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48 at 0x103626F60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_imgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ca1dd2ef-f1aa-4670-92de-c39c481b8463",
    "_uuid": "7d10dfdba4b460ad1e8b20407ea27ac454a7906c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = np.array([np.array(im) for im in ori_imgs])\n",
    "imgs = imgs.reshape(imgs.shape[0], 48, 48, 3) / 255\n",
    "lb = LabelBinarizer().fit(ori_label)\n",
    "label = lb.transform(ori_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "1de7b866-7102-41e8-a92b-86471c5f5706",
    "_uuid": "557c146f2f9c6631acc2f2a907b9b49282a649ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, validX, trainY, validY = train_test_split(imgs, label, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "cf5455a0-c6ef-4795-871f-3a2fff25a569",
    "_uuid": "e1ed352922952c8dd83c1699e6308ca182ae4dd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, Input, Dense, Activation,GlobalMaxPooling2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "3aa8b322-1011-468b-b730-b8cd584576bf",
    "_uuid": "664da8ae62cbeb72bb7b696c8351a62167248206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 46, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 44, 44, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 44, 44, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 18, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 21,628\n",
      "Trainable params: 21,436\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IM_input = Input((48, 48, 3))\n",
    "IM = Conv2D(16, (3, 3))(IM_input)\n",
    "IM = BatchNormalization(axis = 3)(IM)\n",
    "IM = Activation('relu')(IM)\n",
    "IM = Conv2D(16, (3, 3))(IM)\n",
    "IM = BatchNormalization(axis = 3)(IM)\n",
    "IM = Activation('relu')(IM)\n",
    "IM = MaxPooling2D((2, 2), strides=(2, 2))(IM)\n",
    "IM = Conv2D(32, (3, 3))(IM)\n",
    "IM = BatchNormalization(axis = 3)(IM)\n",
    "IM = Activation('relu')(IM)\n",
    "IM = Conv2D(32, (3, 3))(IM)\n",
    "IM = BatchNormalization(axis = 3)(IM)\n",
    "IM = Activation('relu')(IM)\n",
    "IM = GlobalMaxPooling2D()(IM)\n",
    "\n",
    "IM = Dense(64, activation='relu')(IM)\n",
    "IM = Dropout(0.5)(IM)\n",
    "IM = Dense(32, activation='relu')(IM)\n",
    "IM = Dropout(0.5)(IM)\n",
    "IM = Dense(12, activation='softmax')(IM)\n",
    "model = Model(inputs=IM_input, outputs=IM)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "e99dbd17-369c-4617-9d7e-a630f97d79d1",
    "_uuid": "3bdc0043d3c74479763cffb1df6c67df9224ec9c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6f72071b-14cf-4e3f-845f-992be6f7f52c",
    "_uuid": "3776b4ad6a904fa3c204d31e19402d9a2d76dee1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4512 samples, validate on 238 samples\n",
      "Epoch 1/200\n",
      "4096/4512 [==========================>...] - ETA: 5s - loss: 2.7823 - acc: 0.0957"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "modelsave = ModelCheckpoint(\n",
    "    filepath='model.h5', save_best_only=True, verbose=1)\n",
    "model.fit(\n",
    "    trainX, trainY, batch_size=batch_size,\n",
    "    epochs=200, \n",
    "    validation_data=(validX, validY),\n",
    "    callbacks=[annealer, earlystop, modelsave]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1f953f1c-39b3-4160-89aa-e546719f2fef",
    "_uuid": "20834884a92a67eb750e7d70350ca86585abfef3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = glob.glob('../input/test/*.png')\n",
    "test_imgs = []\n",
    "names = []\n",
    "for fn in z:\n",
    "    if fn[-3:] != 'png':\n",
    "        continue\n",
    "    names.append(fn.split('/')[-1])\n",
    "    new_img = Image.open(fn)\n",
    "    test_img = ImageOps.fit(new_img, (48, 48), Image.ANTIALIAS).convert('RGB')\n",
    "    test_imgs.append(test_img)\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "42ee9ca8-ae2f-469e-b881-3962281f6967",
    "_uuid": "b6bff74f20c089f41c3b4a68ccd10df6a48afd2b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timgs = np.array([np.array(im) for im in test_imgs])\n",
    "testX = timgs.reshape(timgs.shape[0], 48, 48, 3) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4036ca95-2dd7-4bc2-83cc-49a61b5516cb",
    "_uuid": "fb2e7a394c6de6daff7963689cec3783a7160846",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(testX)\n",
    "test_y = lb.inverse_transform(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eeec9d02-0100-48aa-b0e8-0e462b547b7c",
    "_uuid": "4e8c0c56c92a518e984a2e8a392c437a4ccb4bc9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ba5e4b1e-5e87-4648-9c3e-c6a68064c4fb",
    "_uuid": "0058bfe0909c8d0fc881602a7edd9c7e16a597f0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'file': names, 'species': test_y})\n",
    "df_sort = df.sort_values(by=['file'])\n",
    "df_sort.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
